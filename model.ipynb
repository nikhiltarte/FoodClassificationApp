{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipData(zipFile, outputLoc):\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    local_zip = zipFile\n",
    "\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "\n",
    "    zip_ref.extractall(outputLoc)\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzipData('datasetZip/dataset.zip', './data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mevaluation\u001b[m\u001b[m \u001b[34mtraining\u001b[m\u001b[m   \u001b[34mvalidation\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9866 images belonging to 11 classes.\n",
      "Found 3430 images belonging to 11 classes.\n",
      "Found 3347 images belonging to 11 classes.\n",
      "Class indices:\n",
      "{'Bread': 0, 'Dairy product': 1, 'Dessert': 2, 'Egg': 3, 'Fried food': 4, 'Meat': 5, 'Noodles-Pasta': 6, 'Rice': 7, 'Seafood': 8, 'Soup': 9, 'Vegetable-Fruit': 10}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the paths to your training, validation, and evaluation directories\n",
    "train_dir = \"data/training\"\n",
    "val_dir = \"data/validation\"\n",
    "eval_dir = \"data/evaluation\"\n",
    "\n",
    "# Define image size and batch size\n",
    "image_size = (224, 224)  # Adjust as needed\n",
    "batch_size = 32\n",
    "\n",
    "# Create ImageDataGenerator instances for training, validation, and evaluation sets\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators for training, validation, and evaluation sets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Assuming you have multiple classes (one-hot encoded)\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "eval_generator = eval_datagen.flow_from_directory(\n",
    "    eval_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Optionally, print class indices\n",
    "print(\"Class indices:\")\n",
    "print(train_generator.class_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "num_classes = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 111, 111, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               11075712  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 11)                1419      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11170379 (42.61 MB)\n",
      "Trainable params: 11170379 (42.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Dense layers\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Optional dropout layer for regularization\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Specify the input shape based on your images\n",
    "input_shape = (224, 224, 3)  # Adjust based on the actual size and number of color channels in your images\n",
    "\n",
    "# Specify the number of classes (assuming a multi-class classification scenario)\n",
    "num_classes = 11  # Number of categories (Bread, Dairy product, ..., Vegetable-Fruit)\n",
    "\n",
    "# Create the model\n",
    "model = create_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 21:33:58.985009: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - ETA: 0s - loss: 2.2712 - accuracy: 0.1984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 21:34:23.573670: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 34s 105ms/step - loss: 2.2712 - accuracy: 0.1984 - val_loss: 2.0373 - val_accuracy: 0.2528\n",
      "Epoch 2/10\n",
      "309/309 [==============================] - 31s 102ms/step - loss: 2.0906 - accuracy: 0.2741 - val_loss: 1.8443 - val_accuracy: 0.3510\n",
      "Epoch 3/10\n",
      "309/309 [==============================] - 32s 102ms/step - loss: 1.9859 - accuracy: 0.3244 - val_loss: 1.8811 - val_accuracy: 0.3233\n",
      "Epoch 4/10\n",
      "309/309 [==============================] - 32s 102ms/step - loss: 1.8946 - accuracy: 0.3615 - val_loss: 1.7912 - val_accuracy: 0.3845\n",
      "Epoch 5/10\n",
      "309/309 [==============================] - 32s 102ms/step - loss: 1.8091 - accuracy: 0.4148 - val_loss: 1.9947 - val_accuracy: 0.3592\n",
      "Epoch 6/10\n",
      "309/309 [==============================] - 32s 103ms/step - loss: 1.7352 - accuracy: 0.4620 - val_loss: 1.9923 - val_accuracy: 0.3723\n",
      "Epoch 7/10\n",
      "309/309 [==============================] - 32s 102ms/step - loss: 1.7798 - accuracy: 0.5003 - val_loss: 2.5117 - val_accuracy: 0.3536\n",
      "Epoch 8/10\n",
      "309/309 [==============================] - 32s 102ms/step - loss: 2.0837 - accuracy: 0.5120 - val_loss: 4.0464 - val_accuracy: 0.2676\n",
      "Epoch 9/10\n",
      "309/309 [==============================] - 32s 102ms/step - loss: 3.2309 - accuracy: 0.5101 - val_loss: 4.4053 - val_accuracy: 0.3676\n",
      "Epoch 10/10\n",
      "309/309 [==============================] - 32s 103ms/step - loss: 4.7889 - accuracy: 0.5110 - val_loss: 6.6192 - val_accuracy: 0.3627\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Adjust the number of epochs as needed\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
